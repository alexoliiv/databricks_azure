# Formula 1 Data Engineering Solution with Azure Databricks and Spark Core ( Under Construction )

![image](https://github.com/alexoliiv/databricks_azure/assets/32246762/fe1e5c11-8fb8-4ee7-992b-fd44f3756005)![Azure Databricks](https://www.google.com/imgres?q=azure%20databricks%20image&imgurl=https%3A%2F%2Fimages.ctfassets.net%2Fxxmwcynv5jdx%2FLT6pxijW8jQOdxeXHEWBS%2Fc78953454f43b0b418960bc44ad78fdd%2Fazure-databricks.jpg%3Fw%3D1600%26h%3D650%26q%3D50%26fit%3Dfill%26f%3Dcenter&imgrefurl=https%3A%2F%2Fwww.azureguru.org%2Fazure-databricks-overview%2F&docid=Z_mds-3bzmjY-M&tbnid=29NOB4R-SOtYQM&vet=12ahUKEwiMuOyR2NSGAxXoqZUCHYXnDeQQM3oECFQQAA..i&w=1600&h=650&hcb=2&ved=2ahUKEwiMuOyR2NSGAxXoqZUCHYXnDeQQM3oECFQQAA)

## Project Overview

This project demonstrates a data engineering solution for analyzing and reporting on Formula 1 motor racing data using Azure Databricks and Spark Core. Azure Databricks provides a unified analytics platform for data engineering, data science, and machine learning, enabling scalable data processing and analysis. Spark Core allows for efficient data manipulation and transformation, making it ideal for handling large datasets.

## Table of Contents

- [Introduction](#introduction)
- [Project Structure](#project-structure)
- [Setup and Configuration](#setup-and-configuration)
- [Data Ingestion](#data-ingestion)
- [Data Engineering](#data-engineering)
  - [Data Cleaning](#data-cleaning)
  - [Data Transformation](#data-transformation)
  - [Data Aggregation](#data-aggregation)
- [Reporting and Analysis](#reporting-and-analysis)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

## Introduction

The goal of this project is to build a comprehensive data engineering pipeline to process and analyze historical Formula 1 racing data. Using Azure Databricks and Spark Core, we will ingest, clean, transform, and aggregate the data, ultimately enabling detailed analysis and reporting on various aspects of Formula 1 races, drivers, teams, and circuits.

## Project Structure

The project repository is organized as follows:

. <br>
├── data <br>
│ └── raw <br>
│ └── formula1_data.csv <br>
├── notebooks <br>
│ └── set-up <br>
│ └── ingestion <br>
├── scripts <br>
│ └── utils.py <br>
├── README.md <br>
└── requirements.txt <br>

